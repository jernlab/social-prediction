---
title: "R Notebook"
output: html_notebook
---

Load functions to use prediction models

```{r}
source("generatingSocialModelPredictions.R")
source("generatingNonSocialModelPredictions.R")
```

<!-- Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*. -->

<!-- When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file). -->

Loading data
```{r}
# Change this number to match the story you'd like to generate predictions for
# 1 = Cake
# 2 = Movie
# 3 = Podcast
# Predictions can take as long as 15 minutes to generate depending on your largest value of t you're predicting for.
storyNum <- 1
filename <- switch (storyNum, "../Data/cakeProbs.csv", "../Data/movieProbs.csv","../Data/podcastProbs.csv")
tList <- switch(storyNum, c(10,20,35,50,70), c(30,45,60,85,100), c(15,30,55,75,105))
probs <- read.csv(filename)

meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
meansFilename <- paste("../Analysis/experimentAverages/", meansFilename, sep="")
storyMeans <- read.csv(meansFilename)
```


Running original model
```{r}
predictions_ns <- sapply(tList, generateNonSocialPrediction)

```


Set-up Social Model parameters & run model
```{r}
b0 <- 10
b1 <- 5
socialModel <- createSocialModel(b0, b1)
predictions_s <- sapply(tList, socialModel)
```

Plotting the predictions on the same graph
```{r}
library(ggplot2)

socDF <- data.frame(t = tList, prediction = predictions_s, cond = "Social")
nsDF <- data.frame(t = tList, prediction = predictions_ns, cond = "NonSocial")
df <- rbind(socDF, nsDF)
ggplot(df,aes(x=t, y=prediction, color = cond)) + geom_point(size=4) + scale_x_continuous(breaks = tList)
```
Custom Grid Search function that minimizes MSE (No cross-validation)

```{r}
gridSearch <- function(x,y,b0s, b1s){
  minMSE = 1000000
  bestb0 = b0s[0]
  bestb1 = b1s[0]
  for(b0 in b0s){
    for(b1 in b1s){
      print(paste("GridSearch - b0:", b0))
      print(paste("GridSearch - b1:", b1))
      mySCModel = createSocialModel(b0, b1)
      scPred = sapply(x, mySCModel) 
      mse = MSE(scPred, y)
      if(mse < minMSE) {
        minMSE = mse
        bestb0 = b0
        bestb1 = b1
        }
    }
  }
  
  return (c(minMSE, bestb0, bestb1))
}
```



Social model cross validation

```{r}
library(dplyr)
expMeans <- storyMeans %>% filter(Context == "Social") %>% select(avg)
expMeans <- expMeans$avg

B0s <- seq(0.5,10,0.5)
B1s <- seq(-5,5, 0.5)
B1s <- B1s[B1s != 0]

start<-timestamp()

res = gridSearch(tList, expMeans, B0s, B1s)

end <- timestamp()

print("Total Completion Time: ", end - start)
print(paste("Best MSE: ", res[1]))
print(paste("b0: ", res[2]))
print(paste("b1: ", res[3]))
```

Testing best parameters

```{r}
rmse <- sqrt(res[1])
B0 <- res[2]
B1 <- res[3]

bestModel <- createSocialModel(B0,B1)
pred <- sapply(tList, bestModel)

RMSE(pred, expMeans)
```

