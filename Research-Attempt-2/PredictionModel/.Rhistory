library(dplyr)
library(stringr)
library(patchwork)
library(ggfx)
plotStory <- function(story){
nonSocialPredictons <- read.csv(paste("../GeneratedPredictions/NonSocial/",story,"Predictions.csv", sep = ""))
library(ggplot2)
df <- read.csv("../Results/Social-NonSocial/Tidy/filtered-tidy-data.csv")
dfGrouped <- df %>% group_by(Level, Story, Context, T_val) %>% filter(Story == .env$story)
socialGroup <- dfGrouped %>% summarise(avg = mean(Prediction))
write.csv2(socialGroup[c(3:5)],paste(story, "Means.csv", sep = ""), row.names = FALSE)
plt <- ggplot(nonSocialPredictons, aes(x=t, y=pred)) + geom_line(size=1.5, color="black")
plt <- plt+ geom_jitter(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context),size=2,alpha=0.4, width=1.2, height=3)
plt <- plt + with_shadow(stat_summary(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context), size=2, fun.data = "mean_cl_boot"), sigma = 3, x_offset = 2, y_offset = 2)
plt <- plt + scale_color_manual(values = c("darkorange", "dodgerblue"))+ xlab('t') +ggtitle(str_to_title(story)) + scale_x_continuous(breaks=socialGroup$T_val)
plt <- plt + ylab('Prediction') + theme(plot.title = element_text(hjust = 0.5))
plt <- plt + theme(
axis.title = element_text(size=14),
axis.text = element_text(size=20),
plot.title = element_text(size=25, hjust = 0.5)
) + ggtitle(str_to_title(story)) + xlab('t')
if(story != "podcast") plt <- plt + theme(legend.position = "none")
if(story != "cake") plt <- plt + ylab("")
return(plt)
}
cakePlt = 0
moviePlt = 0
podcastPlt = 0
for(i in c("cake","movie","podcast")){
storyPlot = plotStory(i)
if(i == "cake") cakePlt = storyPlot
if(i == "movie") moviePlt = storyPlot
if(i == "podcast") podcastPlt = storyPlot
}
cakePlt + moviePlt + podcastPlt
library(dplyr)
library(stringr)
library(patchwork)
library(ggfx)
plotStory <- function(story){
nonSocialPredictons <- read.csv(paste("../GeneratedPredictions/NonSocial/",story,"Predictions.csv", sep = ""))
library(ggplot2)
df <- read.csv("../Results/Social-NonSocial/Tidy/filtered-tidy-data.csv")
dfGrouped <- df %>% group_by(Level, Story, Context, T_val) %>% filter(Story == .env$story)
socialGroup <- dfGrouped %>% summarise(avg = mean(Prediction))
write.csv2(socialGroup[c(3:5)],file=paste(story, "Means.csv", sep = ""), row.names = FALSE)
plt <- ggplot(nonSocialPredictons, aes(x=t, y=pred)) + geom_line(size=1.5, color="black")
plt <- plt+ geom_jitter(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context),size=2,alpha=0.4, width=1.2, height=3)
plt <- plt + with_shadow(stat_summary(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context), size=2, fun.data = "mean_cl_boot"), sigma = 3, x_offset = 2, y_offset = 2)
plt <- plt + scale_color_manual(values = c("darkorange", "dodgerblue"))+ xlab('t') +ggtitle(str_to_title(story)) + scale_x_continuous(breaks=socialGroup$T_val)
plt <- plt + ylab('Prediction') + theme(plot.title = element_text(hjust = 0.5))
plt <- plt + theme(
axis.title = element_text(size=14),
axis.text = element_text(size=20),
plot.title = element_text(size=25, hjust = 0.5)
) + ggtitle(str_to_title(story)) + xlab('t')
if(story != "podcast") plt <- plt + theme(legend.position = "none")
if(story != "cake") plt <- plt + ylab("")
return(plt)
}
cakePlt = 0
moviePlt = 0
podcastPlt = 0
for(i in c("cake","movie","podcast")){
storyPlot = plotStory(i)
if(i == "cake") cakePlt = storyPlot
if(i == "movie") moviePlt = storyPlot
if(i == "podcast") podcastPlt = storyPlot
}
cakePlt + moviePlt + podcastPlt
setwd("~/Research-REPO/social-prediction/Research-Attempt-2/Analysis")
write.csv2(socialGroup[c(3:5)], "cakeMeans.csv")
library(dplyr)
library(stringr)
library(patchwork)
library(ggfx)
plotStory <- function(story){
nonSocialPredictons <- read.csv(paste("../GeneratedPredictions/NonSocial/",story,"Predictions.csv", sep = ""))
library(ggplot2)
df <- read.csv("../Results/Social-NonSocial/Tidy/filtered-tidy-data.csv")
dfGrouped <- df %>% group_by(Level, Story, Context, T_val) %>% filter(Story == .env$story)
socialGroup <- dfGrouped %>% summarise(avg = mean(Prediction))
write.csv2(socialGroup[c(3:5)],file=paste(story, "Means.csv", sep = ""), row.names = FALSE)
plt <- ggplot(nonSocialPredictons, aes(x=t, y=pred)) + geom_line(size=1.5, color="black")
plt <- plt+ geom_jitter(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context),size=2,alpha=0.4, width=1.2, height=3)
plt <- plt + with_shadow(stat_summary(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context), size=2, fun.data = "mean_cl_boot"), sigma = 3, x_offset = 2, y_offset = 2)
plt <- plt + scale_color_manual(values = c("darkorange", "dodgerblue"))+ xlab('t') +ggtitle(str_to_title(story)) + scale_x_continuous(breaks=socialGroup$T_val)
plt <- plt + ylab('Prediction') + theme(plot.title = element_text(hjust = 0.5))
plt <- plt + theme(
axis.title = element_text(size=14),
axis.text = element_text(size=20),
plot.title = element_text(size=25, hjust = 0.5)
) + ggtitle(str_to_title(story)) + xlab('t')
if(story != "podcast") plt <- plt + theme(legend.position = "none")
if(story != "cake") plt <- plt + ylab("")
return(plt)
}
cakePlt = 0
moviePlt = 0
podcastPlt = 0
for(i in c("cake","movie","podcast")){
storyPlot = plotStory(i)
if(i == "cake") cakePlt = storyPlot
if(i == "movie") moviePlt = storyPlot
if(i == "podcast") podcastPlt = storyPlot
}
cakePlt + moviePlt + podcastPlt
library(dplyr)
library(stringr)
library(patchwork)
library(ggfx)
plotStory <- function(story){
nonSocialPredictons <- read.csv(paste("../GeneratedPredictions/NonSocial/",story,"Predictions.csv", sep = ""))
library(ggplot2)
df <- read.csv("../Results/Social-NonSocial/Tidy/filtered-tidy-data.csv")
dfGrouped <- df %>% group_by(Level, Story, Context, T_val) %>% filter(Story == .env$story)
socialGroup <- dfGrouped %>% summarise(avg = mean(Prediction))
write.table(socialGroup[c(3:5)],file=paste(story, "Means.csv", sep = ""), row.names = FALSE, sep=",")
plt <- ggplot(nonSocialPredictons, aes(x=t, y=pred)) + geom_line(size=1.5, color="black")
plt <- plt+ geom_jitter(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context),size=2,alpha=0.4, width=1.2, height=3)
plt <- plt + with_shadow(stat_summary(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context), size=2, fun.data = "mean_cl_boot"), sigma = 3, x_offset = 2, y_offset = 2)
plt <- plt + scale_color_manual(values = c("darkorange", "dodgerblue"))+ xlab('t') +ggtitle(str_to_title(story)) + scale_x_continuous(breaks=socialGroup$T_val)
plt <- plt + ylab('Prediction') + theme(plot.title = element_text(hjust = 0.5))
plt <- plt + theme(
axis.title = element_text(size=14),
axis.text = element_text(size=20),
plot.title = element_text(size=25, hjust = 0.5)
) + ggtitle(str_to_title(story)) + xlab('t')
if(story != "podcast") plt <- plt + theme(legend.position = "none")
if(story != "cake") plt <- plt + ylab("")
return(plt)
}
cakePlt = 0
moviePlt = 0
podcastPlt = 0
for(i in c("cake","movie","podcast")){
storyPlot = plotStory(i)
if(i == "cake") cakePlt = storyPlot
if(i == "movie") moviePlt = storyPlot
if(i == "podcast") podcastPlt = storyPlot
}
cakePlt + moviePlt + podcastPlt
source("generatingSocialModelPredictions.R")
source("generatingNonSocialModelPredictions.R")
source("generatingSocialModelPredictions.R")
source("generatingNonSocialModelPredictions.R")
# Change this number to match the story you'd like to generate predictions for
# 1 = Cake
# 2 = Movie
# 3 = Podcast
# Predictions can take as long as 15 minutes to generate depending on your largest value of t you're predicting for.
storyNum <- 1
filename <- switch (storyNum, "../Data/cakeProbs.csv", "../Data/movieProbs.csv","../Data/podcastProbs.csv")
tList <- switch(storyNum, c(10,20,35,50,70), c(30,45,60,85,100), c(15,30,55,75,105))
probs <- read.csv(filename)
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
storyMeans <- read.csv(paste("./experimentAverages/",meansFilename))
source("generatingSocialModelPredictions.R")
source("generatingNonSocialModelPredictions.R")
# Change this number to match the story you'd like to generate predictions for
# 1 = Cake
# 2 = Movie
# 3 = Podcast
# Predictions can take as long as 15 minutes to generate depending on your largest value of t you're predicting for.
storyNum <- 1
filename <- switch (storyNum, "../Data/cakeProbs.csv", "../Data/movieProbs.csv","../Data/podcastProbs.csv")
tList <- switch(storyNum, c(10,20,35,50,70), c(30,45,60,85,100), c(15,30,55,75,105))
probs <- read.csv(filename)
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
storyMeans <- read.csv(paste("./experimentAverages/",meansFilename, sep=""))
setwd("~/Research-REPO/social-prediction/Research-Attempt-2/PredictionModel")
storyMeans <- read.csv(paste("./experimentAverages/",meansFilename, sep=""))
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
storyMeans <- read.csv(paste("./experimentAverages/", meansFilename, sep=""))
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
meansFilename <- paste("./experimentAverages/", meansFilename, sep="")
storyMeans <- read.csv(meansFilename)
meansFilename <- paste("experimentAverages/", meansFilename, sep="")
storyMeans <- read.csv(meansFilename)
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
meansFilename <- paste("experimentAverages/", meansFilename, sep="")
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
meansFilename <- paste("/experimentAverages/", meansFilename, sep="")
storyMeans <- read.csv(meansFilename)
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
meansFilename <- paste("../Analysis/experimentAverages/", meansFilename, sep="")
storyMeans <- read.csv(meansFilename)
View(storyMeans)
storyMeans
install.packages('metrics')
library(MLmetrics)
View(storyMeans)
View(storyMeans)
library(dplyr)
means <- storyMeans %>% filter(context == "Social")
means <- storyMeans %>% filter(Context == "Social")
View(means)
means <- storyMeans %>% filter(Context == "Social") %>% select(avg)
View(means)
as.vector(means)
as.vector(means)
as.array(means)
as.array(means$avg)
expMeans <- storyMeans %>% filter(Context == "Social") %>% select(avg)
expMeans <- expMeans$avg
source("generatingSocialModelPredictions.R")
source("generatingNonSocialModelPredictions.R")
# Change this number to match the story you'd like to generate predictions for
# 1 = Cake
# 2 = Movie
# 3 = Podcast
# Predictions can take as long as 15 minutes to generate depending on your largest value of t you're predicting for.
storyNum <- 1
filename <- switch (storyNum, "../Data/cakeProbs.csv", "../Data/movieProbs.csv","../Data/podcastProbs.csv")
tList <- switch(storyNum, c(10,20,35,50,70), c(30,45,60,85,100), c(15,30,55,75,105))
probs <- read.csv(filename)
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
meansFilename <- paste("../Analysis/experimentAverages/", meansFilename, sep="")
storyMeans <- read.csv(meansFilename)
predictions_ns <- sapply(tList, generateNonSocialPrediction)
b0 <- 10
b1 <- 5
socialModel <- createSocialModel(b0, b1)
predictions_s <- sapply(tList, socialModel)
library(ggplot2)
socDF <- data.frame(t = tList, prediction = predictions_s, cond = "Social")
nsDF <- data.frame(t = tList, prediction = predictions_ns, cond = "NonSocial")
df <- rbind(socDF, nsDF)
ggplot(df,aes(x=t, y=prediction, color = cond)) + geom_point(size=4) + scale_x_continuous(breaks = tList)
library(dplyr)
expMeans <- storyMeans %>% filter(Context == "Social") %>% select(avg)
expMeans <- expMeans$avg
MSE(expMeans, predictions_s)
gridSearch <- function(x,y,b0s, b1s){
minMSE = 1000000
bestb0 = b0s[0]
bestb1 = b1s[0]
for(b0 in b0s){
for(b1 in b1s){
mySCModel = createSocialModel(b0, b1)
scPred = sapply(x, mySCModel)
mse = MSE(scPred, y)
if(mse < minMSE) {
minMSE = mse
bestb0 = b0
bestb1 = b1
}
}
}
}
gridSearch <- function(x,y,b0s, b1s){
minMSE = 1000000
bestb0 = b0s[0]
bestb1 = b1s[0]
for(b0 in b0s){
for(b1 in b1s){
mySCModel = createSocialModel(b0, b1)
scPred = sapply(x, mySCModel)
mse = MSE(scPred, y)
if(mse < minMSE) {
minMSE = mse
bestb0 = b0
bestb1 = b1
}
}
}
return (c(minMSE, bestb0, bestb1))
}
gridSearch <- function(x,y,b0s, b1s){
minMSE = 1000000
bestb0 = b0s[0]
bestb1 = b1s[0]
for(b0 in b0s){
for(b1 in b1s){
mySCModel = createSocialModel(b0, b1)
scPred = sapply(x, mySCModel)
mse = MSE(scPred, y)
if(mse < minMSE) {
minMSE = mse
bestb0 = b0
bestb1 = b1
}
}
}
return (c(minMSE, bestb0, bestb1))
}
library(dplyr)
expMeans <- storyMeans %>% filter(Context == "Social") %>% select(avg)
expMeans <- expMeans$avg
B0s <- seq(1,2,0.3)
B1s <- seq(-4,3, 0.3)
start<-timestamp()
##------ Tue Apr 26 22:58:59 2022 ------##
res = gridSearch(tList, expMeans, B0s, B1s)
end <- timestamp()
##------ Tue Apr 26 23:00:14 2022 ------##
print("Total Completion Time: ", end - start)
gridSearch <- function(x,y,b0s, b1s){
minMSE = 1000000
bestb0 = b0s[0]
bestb1 = b1s[0]
for(b0 in b0s){
for(b1 in b1s){
mySCModel = createSocialModel(b0, b1)
scPred = sapply(x, mySCModel)
mse = MSE(scPred, y)
if(mse < minMSE) {
minMSE = mse
bestb0 = b0
bestb1 = b1
}
}
}
return (c(minMSE, bestb0, bestb1))
}
library(dplyr)
expMeans <- storyMeans %>% filter(Context == "Social") %>% select(avg)
expMeans <- expMeans$avg
B0s <- seq(1,2,0.3)
B1s <- seq(-4,-3, 0.3)
start<-timestamp()
##------ Tue Apr 26 23:00:30 2022 ------##
res = gridSearch(tList, expMeans, B0s, B1s)
end <- timestamp()
##------ Tue Apr 26 23:02:36 2022 ------##
print("Total Completion Time: ", end - start)
print("Best MSE: ", res[1])
print(paste("Best MSE: ", res[1]))
print(paste("b0: ", res[2]))
print(paste("b1: ", res[3]))
source("generatingSocialModelPredictions.R")
source("generatingNonSocialModelPredictions.R")
# Change this number to match the story you'd like to generate predictions for
# 1 = Cake
# 2 = Movie
# 3 = Podcast
# Predictions can take as long as 15 minutes to generate depending on your largest value of t you're predicting for.
storyNum <- 1
filename <- switch (storyNum, "../Data/cakeProbs.csv", "../Data/movieProbs.csv","../Data/podcastProbs.csv")
tList <- switch(storyNum, c(10,20,35,50,70), c(30,45,60,85,100), c(15,30,55,75,105))
probs <- read.csv(filename)
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
meansFilename <- paste("../Analysis/experimentAverages/", meansFilename, sep="")
storyMeans <- read.csv(meansFilename)
predictions_ns <- sapply(tList, generateNonSocialPrediction)
b0 <- 10
b1 <- 5
socialModel <- createSocialModel(b0, b1)
predictions_s <- sapply(tList, socialModel)
library(ggplot2)
socDF <- data.frame(t = tList, prediction = predictions_s, cond = "Social")
nsDF <- data.frame(t = tList, prediction = predictions_ns, cond = "NonSocial")
df <- rbind(socDF, nsDF)
ggplot(df,aes(x=t, y=prediction, color = cond)) + geom_point(size=4) + scale_x_continuous(breaks = tList)
gridSearch <- function(x,y,b0s, b1s){
minMSE = 1000000
bestb0 = b0s[0]
bestb1 = b1s[0]
for(b0 in b0s){
for(b1 in b1s){
mySCModel = createSocialModel(b0, b1)
scPred = sapply(x, mySCModel)
mse = MSE(scPred, y)
if(mse < minMSE) {
minMSE = mse
bestb0 = b0
bestb1 = b1
}
}
}
return (c(minMSE, bestb0, bestb1))
}
library(dplyr)
expMeans <- storyMeans %>% filter(Context == "Social") %>% select(avg)
expMeans <- expMeans$avg
B0s <- seq(0,10,0.5)
B1s <- seq(-5,5, 0.5)
start<-timestamp()
##------ Wed Apr 27 13:36:43 2022 ------##
res = gridSearch(tList, expMeans, B0s, B1s)
source("generatingSocialModelPredictions.R")
source("generatingNonSocialModelPredictions.R")
# Change this number to match the story you'd like to generate predictions for
# 1 = Cake
# 2 = Movie
# 3 = Podcast
# Predictions can take as long as 15 minutes to generate depending on your largest value of t you're predicting for.
storyNum <- 1
filename <- switch (storyNum, "../Data/cakeProbs.csv", "../Data/movieProbs.csv","../Data/podcastProbs.csv")
tList <- switch(storyNum, c(10,20,35,50,70), c(30,45,60,85,100), c(15,30,55,75,105))
probs <- read.csv(filename)
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
meansFilename <- paste("../Analysis/experimentAverages/", meansFilename, sep="")
storyMeans <- read.csv(meansFilename)
predictions_ns <- sapply(tList, generateNonSocialPrediction)
b0 <- 10
b1 <- 5
socialModel <- createSocialModel(b0, b1)
predictions_s <- sapply(tList, socialModel)
library(ggplot2)
socDF <- data.frame(t = tList, prediction = predictions_s, cond = "Social")
nsDF <- data.frame(t = tList, prediction = predictions_ns, cond = "NonSocial")
df <- rbind(socDF, nsDF)
ggplot(df,aes(x=t, y=prediction, color = cond)) + geom_point(size=4) + scale_x_continuous(breaks = tList)
gridSearch <- function(x,y,b0s, b1s){
minMSE = 1000000
bestb0 = b0s[0]
bestb1 = b1s[0]
for(b0 in b0s){
for(b1 in b1s){
print(paste("GridSearch - b0:", b0))
print(paste("GridSearch - b1:", b1))
mySCModel = createSocialModel(b0, b1)
scPred = sapply(x, mySCModel)
mse = MSE(scPred, y)
if(mse < minMSE) {
minMSE = mse
bestb0 = b0
bestb1 = b1
}
}
}
return (c(minMSE, bestb0, bestb1))
}
library(dplyr)
expMeans <- storyMeans %>% filter(Context == "Social") %>% select(avg)
expMeans <- expMeans$avg
B0s <- seq(0.5,10,0.5)
B1s <- seq(-5,5, 0.5)
start<-timestamp()
##------ Wed Apr 27 13:49:44 2022 ------##
res = gridSearch(tList, expMeans, B0s, B1s)
B1s[x == 0]
B1s[B1s[x] == 0]
B1s[B1s == 0]
B1s[B1s != 0]
B0s <- seq(0.5,10,0.5)
B1s <- seq(-5,-0.5, 0.5)
B0s <- seq(0.5,10,0.5)
B1s <- seq(-5,5, 0.5)
B1s <- B1s[B1s != 0]
source("generatingSocialModelPredictions.R")
source("generatingNonSocialModelPredictions.R")
# Change this number to match the story you'd like to generate predictions for
# 1 = Cake
# 2 = Movie
# 3 = Podcast
# Predictions can take as long as 15 minutes to generate depending on your largest value of t you're predicting for.
storyNum <- 1
filename <- switch (storyNum, "../Data/cakeProbs.csv", "../Data/movieProbs.csv","../Data/podcastProbs.csv")
tList <- switch(storyNum, c(10,20,35,50,70), c(30,45,60,85,100), c(15,30,55,75,105))
probs <- read.csv(filename)
meansFilename <- switch(storyNum, "cakeMeans.csv", "movieMeans.csv", "podcastMeans.csv")
meansFilename <- paste("../Analysis/experimentAverages/", meansFilename, sep="")
storyMeans <- read.csv(meansFilename)
predictions_ns <- sapply(tList, generateNonSocialPrediction)
b0 <- 10
b1 <- 5
socialModel <- createSocialModel(b0, b1)
predictions_s <- sapply(tList, socialModel)
library(ggplot2)
socDF <- data.frame(t = tList, prediction = predictions_s, cond = "Social")
nsDF <- data.frame(t = tList, prediction = predictions_ns, cond = "NonSocial")
df <- rbind(socDF, nsDF)
ggplot(df,aes(x=t, y=prediction, color = cond)) + geom_point(size=4) + scale_x_continuous(breaks = tList)
gridSearch <- function(x,y,b0s, b1s){
minMSE = 1000000
bestb0 = b0s[0]
bestb1 = b1s[0]
for(b0 in b0s){
for(b1 in b1s){
print(paste("GridSearch - b0:", b0))
print(paste("GridSearch - b1:", b1))
mySCModel = createSocialModel(b0, b1)
scPred = sapply(x, mySCModel)
mse = MSE(scPred, y)
if(mse < minMSE) {
minMSE = mse
bestb0 = b0
bestb1 = b1
}
}
}
return (c(minMSE, bestb0, bestb1))
}
library(dplyr)
expMeans <- storyMeans %>% filter(Context == "Social") %>% select(avg)
expMeans <- expMeans$avg
B0s <- seq(0.5,10,0.5)
B1s <- seq(-5,5, 0.5)
B1s <- B1s[B1s != 0]
start<-timestamp()
##------ Wed Apr 27 14:49:25 2022 ------##
res = gridSearch(tList, expMeans, B0s, B1s)
end <- timestamp()
##------ Wed Apr 27 15:35:59 2022 ------##
print("Total Completion Time: ", end - start)
print(paste("Best MSE: ", res[1]))
print(paste("b0: ", res[2]))
print(paste("b1: ", res[3]))
print(paste("b0: ", res[2]))
rmse <- sqrt(res[1])
B0 <- res[2]
B1 <- res[3]
bestModel <- createSocialModel(B0,B1)
pred <- sapply(tList, bestModel)
rmse <- sqrt(res[1])
B0 <- res[2]
B1 <- res[3]
bestModel <- createSocialModel(B0,B1)
pred <- sapply(tList, bestModel)
RMSE(pred, expMeans)
