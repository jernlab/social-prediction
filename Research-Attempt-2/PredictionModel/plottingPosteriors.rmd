---
title: "R Notebook"
output: html_notebook
---

Generating posteriors for non-social and social models p(t_total | t) for all t_total for a fixed value t (set below)
```{r}
t <- 20

cakeProbs <- read.csv("cakeProbs.csv")
cakeRatings <- read.csv("interpolatedCakeRatings.csv")

maxTtotal <- max(cakeProbs[[1]])

contextRating <- cakeRatings[[2]][t]
normalizedContextRating <- contextRating/8
```


##Calculating Social Posteriors

Code for generating social predictions differs from non-social prediction only 
by taking an additional argument that is p(c | t), the rating we got from participants in experiment 1 divided by 8
```{r}
computeModelPosterior<-function(t_total, t, t_total_info, contextRatingGivenT){
  #t_total        : The value of t_total in P(t_total | t)
  #t              : The value of t in P(t_total | t)
  #gamma           : gamma parameter (Not used in generating these predictions, leftover from implementation of original model)
  #t_total_info   : a Domain Size x 2 vector, 1st column are t_total values, 
  #                 2nd is P(t_total)
  #flag           : The story (cake, bus, drive, train) we're calculating posterior for
  #                             1     2     3      4
  
  startIndex = 0
  
  #Vector of all t_total values
  t_total_vals_vec = t_total_info[1]
  
  #Vector of all t_total_probs
  t_total_probs_vec = t_total_info[2]
  num_rows = nrow(t_total_vals_vec)
  
  for(i in (1:num_rows)){
    if(t_total_info[i,1] >= t){
      startIndex = i
      break
    }
  }
  
  likelihood = contextRatingGivenT * sum(t_total_probs_vec[c(startIndex:num_rows),])
  
  t_prior = 0
  given_t_total_prior = 0
  
  #P(t) = sum of p(t_total)/t_total
  t_prior = t_total_info[[2]][c(startIndex:num_rows)] / t_total_info[[1]][c(startIndex:num_rows)]
  
  for(i in (startIndex:num_rows)){
    #t_prior = t_prior + (t_total_probs_vec[i,]/t_total_vals_vec[i,])
    #Storing the t_total probability for the t_total passed as the function's parameter
    if(t_total_vals_vec[i,] == t_total) given_t_total_prior = t_total_probs_vec[i,]
  }
  
  
  #Bayes Rules
  return (likelihood * given_t_total_prior) #/ t_prior
}
```

##Calculating Non-Social Posteriors

```{r}
computeModelPosterior_deriv<-function(t_total, t, t_total_info){
  #t_total        : The value of t_total in P(t_total | t)
  #t              : The value of t in P(t_total | t)
  #gamma           : gamma parameter (Not used in generating these predictions, leftover from implementation of original model)
  #t_total_info   : a Domain Size x 2 vector, 1st column are t_total values, 
  #                 2nd is P(t_total)
  
  startIndex = 0
  
  #Vector of all t_total values
  t_total_vals_vec = t_total_info[1]
  
  #Vector of all t_total_probs
  t_total_probs_vec = t_total_info[2]
  num_rows = nrow(t_total_vals_vec)
  
  for(i in (1:num_rows)){
    if(t_total_info[i,1] >= t){
      startIndex = i
      break
    }
  }
  
  likelihood = 1/t_total #Otherwise generate non-social predictions
  
  t_prior = 0
  given_t_total_prior = 0
  
  #P(t) = sum of p(t_total)/t_total
  for(i in (startIndex:num_rows)){
    t_prior = t_prior + (t_total_probs_vec[i,]/t_total_vals_vec[i,])
    #Storing the t_total probability for the t_total passed as the function's parameter
    if(t_total_vals_vec[i,] == t_total) given_t_total_prior = t_total_probs_vec[i,]
  }
  
  #Bayes Rules
  return (likelihood * given_t_total_prior) / t_prior
}
```

Generating Social Posteriors

```{r}
socialPosteriors <- data.frame(T_total = c(t:maxTtotal), Posterior = c(t:maxTtotal))
nonSocialPosteriors <- data.frame(T_total = c(t:maxTtotal), Posterior = c(t:maxTtotal))

for(t_total in c(t:maxTtotal)){
  nonSocialPosteriors$Posterior[[t_total - t + 1]] <- computeModelPosterior_deriv(t_total, t, cakeProbs)
  socialPosteriors$Posterior[[t_total - t + 1]] <- computeModelPosterior(t_total, t, cakeProbs, normalizedContextRating)
}


#Normalize posteriors since they aren't true probability distributions
socialPosteriors$Posterior = socialPosteriors$Posterior / sum(socialPosteriors$Posterior)
nonSocialPosteriors$Posterior = nonSocialPosteriors$Posterior / sum(nonSocialPosteriors$Posterior)
## Plotting

ggplot(socialPosteriors, aes(x=T_total,y=Posterior))+ geom_col(data=nonSocialPosteriors, aes(x=T_total, y=Posterior),color="red",size=3) + geom_col(color="blue",size=1) + ggtitle(paste("P(t_total | t) w/ t = ", t))
```

## Checking ratio of posteriors

Theoretically, if the distributions are actually different, and not just scaled versions of one another, the ratios of social:non-social posteriors should vary.

```{r}
socialNonSocialRatio <- socialPosteriors$Posterior / nonSocialPosteriors$Posterior
filteredRatios <- socialNonSocialRatio[!is.na(socialNonSocialRatio)]

unique(filteredRatios)
unique(filteredRatios[1] - filteredRatios[2])
```



Social prediction
```{r}
  sum = 0
  pTtotalGivenT <- socialPosteriors$Posterior
  medi <- sum(pTtotalGivenT)/2
  idx <- 1
  lenpTtotal <- length(pTtotalGivenT)
  while (sum < medi && idx < lenpTtotal) {
    sum = sum + pTtotalGivenT[idx]
    idx = idx + 1
  }
  
  pred <- socialPosteriors$T_total[idx-1]
```