#=======================================================
#Linear-Mixed Modeling
#=======================================================
lmeDf <- makeLMECompatible(nonFilteredData)
lme4::lmer(Guess ~ Context + Domain + Level + (1|Subject), data=lmeDf)
install.packages("installr")
library(installr)
updateR()
install.packages("RWeka")
print("Hello World")
2+2
print("Hello World")
library(tidyverse)
setwd("~/")
crayjay <- read.csv("crayfish_lab.csv")
crayjay <- read.csv("crawfish_lab.csv")
crayjay$bpm <- crayjay$誰..bpm
crayjay$誰..bpm <- NULL
crayjay
crayjay <- read.csv("crawfish_lab.csv")
crayjay$bpm <- crayjay$誰..bpm
crayjay$誰..bpm <- NULL
crayjay
crayjay$drug <- factor(crayjay$drug)
crayjay
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line()
crayplot
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line(size = 2)
crayplot
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line(size = 1.1)
crayplot
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line(size = 0.3)
crayplot
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line(size = 0.5)
crayplot
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line(size = 0.7)
crayplot
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line(size = 1.02)
crayplot
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line(size = 1)
crayplot
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line(size = 1) + xlab("Time Elapsed (s)") + ylab("Percent Change BPM from Rest")
crayplot
crayjay$t_drug <- factor(crayjay$t_drug)
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug, shape = t_drug), size = 3.4) + geom_line(size = 1) + xlab("Time Elapsed (s)") + ylab("Percent Change BPM from Rest")
crayjay$t_drug <- factor(crayjay$t_drug)
crayplot
crayplot <- ggplot(data = crayjay, mapping = aes(x = t_elapsed, y = percent_change)) + geom_point(aes(color = drug), size = 3.4) + geom_line(size = 1) + xlab("Time Elapsed (s)") + ylab("Percent Change BPM from Rest")
crayplot
#Non-Social Model Predictions
computeModelPosterior_deriv<-function(t_total, t, t_total_info, flag){
#t_total        : The value of t_total in P(t_total | t)
#t              : The value of t in P(t_total | t)
#gamma           : gamma parameter (Not used in generating these predictions, leftover from implementation of original model)
#t_total_info   : a Domain Size x 2 vector, 1st column are t_total values,
#                 2nd is P(t_total)
#flag           : The story (cake, bus, drive, train) we're calculating posterior for
#                             1     2     3      4
startIndex = 0
#Vector of all t_total values
t_total_vals_vec = t_total_info[1]
#Vector of all t_total_probs
t_total_probs_vec = t_total_info[2]
num_rows = nrow(t_total_vals_vec)
for(i in (1:num_rows)){
if(t_total_info[i,1] >= t){
startIndex = i
break
}
}
para = 0.3
#The cake, bus, and drive stories all use the same utility function
if(flag == 1 || flag == 3 || flag == 2){
if(t_total - t != 0){
util = exp(1/(t_total - t))
util = util / (exp((t_total - t)*para) + util)
}
else {
util = 1
}
likelihood = (1/t_total) * util
}
# The utitlity function for the train story
else if(flag == 4){
util = exp(t_total-t)
util = util / (exp((1/(t_total - t))*para) + util)
likelihood = (1/t_total) * util
}
else likelihood = 1/t_total #Otherwise generate non-social predictions
t_prior = 0
given_t_total_prior = 0
#P(t) = sum of p(t_total)/t_total
for(i in (1:num_rows)){
t_prior = t_prior + (t_total_probs_vec[i,]/t_total_vals_vec[i,])
#Storing the t_total probability for the t_total passed as the function's parameter
if(t_total_vals_vec[i,] == t_total) given_t_total_prior = t_total_probs_vec[i,]
}
#Bayes Rules
return (likelihood * given_t_total_prior) / t_prior
}
generateNonSocialPrediction <- function(t, story=0){
# t <- 50
# t_total <- 70
data_file_path <- "C:\\Users\\paynesc\\Documents\\research\\Attempt2\\data\\Podcasts\\podcastProbs.csv"
data <- read.csv(data_file_path, header = TRUE)
maxTtotal <- max(data$runtime)
x_space <- c(t:maxTtotal)
idx <- 1
allTtotalProbsGivenT <- data.frame(Ttotal = x_space, pTtotalGivenT = rep(maxTtotal-t))
for(i in x_space){
probTtotalGivenT <- computeModelPosterior_deriv(i, t, data, 5)
allTtotalProbsGivenT$pTtotalGivenT[idx] <- probTtotalGivenT
# print(probTtotalGivenT)
idx <- idx + 1
}
#Predict Median
sum = 0
pTtotalGivenT <- allTtotalProbsGivenT$pTtotalGivenT
medi <- sum(pTtotalGivenT)/2
idx = 1
while (sum < medi && idx < length(pTtotalGivenT)) {
sum = sum + pTtotalGivenT[idx]
idx = idx + 1
}
#pred <- paste("Prediction for T-total given T = ", t, ": ", allTtotalProbsGivenT$Ttotal[idx-1])
pred <- allTtotalProbsGivenT$Ttotal[idx-1]
# print(pred)
return(pred)
}
generateMultipleNonSocialPredictions <- function(t, tMax, tMin=NULL){
# t <- 50
# tMax <- 100
tVals <- 0
if(!is.null(tMin)){
tVals <- c(tMin:tMax)
}
else{
tVals <- c(t:tMax)
}
#print(range(tVals))
df <- data.frame(t=tVals, pred=rep(0, length(tVals)))
ix = 1
for(tVal in tVals){
pred = generateNonSocialPrediction(t=tVal)
df$pred[ix] <- pred
ix = ix + 1
}
return(df)
}
df <- generateMultipleNonSocialPredictions(t=30,tMax=90)
library(ggplot2)
plt <- ggplot(data = df) + geom_line(mapping = aes(x=t, y=pred), color="blue", size=1.3) + ylab("Prediction") + ggtitle("Non-Social Podcast Duration Predictions") + theme(axis.title.x = element_text(size=20, face="bold"),
axis.title.y = element_text(size=20, face="bold"),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
plot.title = element_text(size=25, face="bold")
)+coord_cartesian(xlim=c(0,301))
plt
#Non-Social Model Predictions
computeModelPosterior_deriv<-function(t_total, t, t_total_info, flag){
#t_total        : The value of t_total in P(t_total | t)
#t              : The value of t in P(t_total | t)
#gamma           : gamma parameter (Not used in generating these predictions, leftover from implementation of original model)
#t_total_info   : a Domain Size x 2 vector, 1st column are t_total values,
#                 2nd is P(t_total)
#flag           : The story (cake, bus, drive, train) we're calculating posterior for
#                             1     2     3      4
startIndex = 0
#Vector of all t_total values
t_total_vals_vec = t_total_info[1]
#Vector of all t_total_probs
t_total_probs_vec = t_total_info[2]
num_rows = nrow(t_total_vals_vec)
for(i in (1:num_rows)){
if(t_total_info[i,1] >= t){
startIndex = i
break
}
}
para = 0.3
#The cake, bus, and drive stories all use the same utility function
if(flag == 1 || flag == 3 || flag == 2){
if(t_total - t != 0){
util = exp(1/(t_total - t))
util = util / (exp((t_total - t)*para) + util)
}
else {
util = 1
}
likelihood = (1/t_total) * util
}
# The utitlity function for the train story
else if(flag == 4){
util = exp(t_total-t)
util = util / (exp((1/(t_total - t))*para) + util)
likelihood = (1/t_total) * util
}
else likelihood = 1/t_total #Otherwise generate non-social predictions
t_prior = 0
given_t_total_prior = 0
#P(t) = sum of p(t_total)/t_total
for(i in (1:num_rows)){
t_prior = t_prior + (t_total_probs_vec[i,]/t_total_vals_vec[i,])
#Storing the t_total probability for the t_total passed as the function's parameter
if(t_total_vals_vec[i,] == t_total) given_t_total_prior = t_total_probs_vec[i,]
}
#Bayes Rules
return (likelihood * given_t_total_prior) / t_prior
}
generateNonSocialPrediction <- function(t, story=0){
# t <- 50
# t_total <- 70
data_file_path <- "C:\\Users\\paynesc\\Documents\\research\\Attempt2\\data\\Podcasts\\podcastProbs.csv"
data <- read.csv(data_file_path, header = TRUE)
maxTtotal <- max(data$runtime)
x_space <- c(t:maxTtotal)
idx <- 1
allTtotalProbsGivenT <- data.frame(Ttotal = x_space, pTtotalGivenT = rep(maxTtotal-t))
for(i in x_space){
probTtotalGivenT <- computeModelPosterior_deriv(i, t, data, 5)
allTtotalProbsGivenT$pTtotalGivenT[idx] <- probTtotalGivenT
# print(probTtotalGivenT)
idx <- idx + 1
}
#Predict Median
sum = 0
pTtotalGivenT <- allTtotalProbsGivenT$pTtotalGivenT
medi <- sum(pTtotalGivenT)/2
idx = 1
while (sum < medi && idx < length(pTtotalGivenT)) {
sum = sum + pTtotalGivenT[idx]
idx = idx + 1
}
#pred <- paste("Prediction for T-total given T = ", t, ": ", allTtotalProbsGivenT$Ttotal[idx-1])
pred <- allTtotalProbsGivenT$Ttotal[idx-1]
# print(pred)
return(pred)
}
generateMultipleNonSocialPredictions <- function(t, tMax, tMin=NULL){
# t <- 50
# tMax <- 100
tVals <- 0
if(!is.null(tMin)){
tVals <- c(tMin:tMax)
}
else{
tVals <- c(t:tMax)
}
#print(range(tVals))
df <- data.frame(t=tVals, pred=rep(0, length(tVals)))
ix = 1
for(tVal in tVals){
pred = generateNonSocialPrediction(t=tVal)
df$pred[ix] <- pred
ix = ix + 1
}
return(df)
}
df <- generateMultipleNonSocialPredictions(t=30,tMax=90)
#Non-Social Model Predictions
computeModelPosterior_deriv<-function(t_total, t, t_total_info, flag){
#t_total        : The value of t_total in P(t_total | t)
#t              : The value of t in P(t_total | t)
#gamma           : gamma parameter (Not used in generating these predictions, leftover from implementation of original model)
#t_total_info   : a Domain Size x 2 vector, 1st column are t_total values,
#                 2nd is P(t_total)
#flag           : The story (cake, bus, drive, train) we're calculating posterior for
#                             1     2     3      4
startIndex = 0
#Vector of all t_total values
t_total_vals_vec = t_total_info[1]
#Vector of all t_total_probs
t_total_probs_vec = t_total_info[2]
num_rows = nrow(t_total_vals_vec)
for(i in (1:num_rows)){
if(t_total_info[i,1] >= t){
startIndex = i
break
}
}
para = 0.3
#The cake, bus, and drive stories all use the same utility function
if(flag == 1 || flag == 3 || flag == 2){
if(t_total - t != 0){
util = exp(1/(t_total - t))
util = util / (exp((t_total - t)*para) + util)
}
else {
util = 1
}
likelihood = (1/t_total) * util
}
# The utitlity function for the train story
else if(flag == 4){
util = exp(t_total-t)
util = util / (exp((1/(t_total - t))*para) + util)
likelihood = (1/t_total) * util
}
else likelihood = 1/t_total #Otherwise generate non-social predictions
t_prior = 0
given_t_total_prior = 0
#P(t) = sum of p(t_total)/t_total
for(i in (1:num_rows)){
t_prior = t_prior + (t_total_probs_vec[i,]/t_total_vals_vec[i,])
#Storing the t_total probability for the t_total passed as the function's parameter
if(t_total_vals_vec[i,] == t_total) given_t_total_prior = t_total_probs_vec[i,]
}
#Bayes Rules
return (likelihood * given_t_total_prior) / t_prior
}
generateNonSocialPrediction <- function(t, story=0){
# t <- 50
# t_total <- 70
data_file_path <- "C:\\Users\\paynesc\\Documents\\research\\Attempt2\\data\\Movies\\movieProbs.csv"
data <- read.csv(data_file_path, header = TRUE)
maxTtotal <- max(data$runtime)
x_space <- c(t:maxTtotal)
idx <- 1
allTtotalProbsGivenT <- data.frame(Ttotal = x_space, pTtotalGivenT = rep(maxTtotal-t))
for(i in x_space){
probTtotalGivenT <- computeModelPosterior_deriv(i, t, data, 5)
allTtotalProbsGivenT$pTtotalGivenT[idx] <- probTtotalGivenT
# print(probTtotalGivenT)
idx <- idx + 1
}
#Predict Median
sum = 0
pTtotalGivenT <- allTtotalProbsGivenT$pTtotalGivenT
medi <- sum(pTtotalGivenT)/2
idx = 1
while (sum < medi && idx < length(pTtotalGivenT)) {
sum = sum + pTtotalGivenT[idx]
idx = idx + 1
}
#pred <- paste("Prediction for T-total given T = ", t, ": ", allTtotalProbsGivenT$Ttotal[idx-1])
pred <- allTtotalProbsGivenT$Ttotal[idx-1]
# print(pred)
return(pred)
}
generateMultipleNonSocialPredictions <- function(t, tMax, tMin=NULL){
# t <- 50
# tMax <- 100
tVals <- 0
if(!is.null(tMin)){
tVals <- c(tMin:tMax)
}
else{
tVals <- c(t:tMax)
}
#print(range(tVals))
df <- data.frame(t=tVals, pred=rep(0, length(tVals)))
ix = 1
for(tVal in tVals){
pred = generateNonSocialPrediction(t=tVal)
df$pred[ix] <- pred
ix = ix + 1
}
return(df)
}
df <- generateMultipleNo
#Non-Social Model Predictions
computeModelPosterior_deriv<-function(t_total, t, t_total_info, flag){
#t_total        : The value of t_total in P(t_total | t)
#t              : The value of t in P(t_total | t)
#gamma           : gamma parameter (Not used in generating these predictions, leftover from implementation of original model)
#t_total_info   : a Domain Size x 2 vector, 1st column are t_total values,
#                 2nd is P(t_total)
#flag           : The story (cake, bus, drive, train) we're calculating posterior for
#                             1     2     3      4
startIndex = 0
#Vector of all t_total values
t_total_vals_vec = t_total_info[1]
#Vector of all t_total_probs
t_total_probs_vec = t_total_info[2]
num_rows = nrow(t_total_vals_vec)
for(i in (1:num_rows)){
if(t_total_info[i,1] >= t){
startIndex = i
break
}
}
para = 0.3
#The cake, bus, and drive stories all use the same utility function
if(flag == 1 || flag == 3 || flag == 2){
if(t_total - t != 0){
util = exp(1/(t_total - t))
util = util / (exp((t_total - t)*para) + util)
}
else {
util = 1
}
likelihood = (1/t_total) * util
}
# The utitlity function for the train story
else if(flag == 4){
util = exp(t_total-t)
util = util / (exp((1/(t_total - t))*para) + util)
likelihood = (1/t_total) * util
}
else likelihood = 1/t_total #Otherwise generate non-social predictions
t_prior = 0
given_t_total_prior = 0
#P(t) = sum of p(t_total)/t_total
for(i in (1:num_rows)){
t_prior = t_prior + (t_total_probs_vec[i,]/t_total_vals_vec[i,])
#Storing the t_total probability for the t_total passed as the function's parameter
if(t_total_vals_vec[i,] == t_total) given_t_total_prior = t_total_probs_vec[i,]
}
#Bayes Rules
return (likelihood * given_t_total_prior) / t_prior
}
generateNonSocialPrediction <- function(t, story=0){
# t <- 50
# t_total <- 70
data_file_path <- "C:\\Users\\paynesc\\Documents\\research\\Attempt2\\data\\Movies\\movieProbs.csv"
data <- read.csv(data_file_path, header = TRUE)
maxTtotal <- max(data$runtime)
x_space <- c(t:maxTtotal)
idx <- 1
allTtotalProbsGivenT <- data.frame(Ttotal = x_space, pTtotalGivenT = rep(maxTtotal-t))
for(i in x_space){
probTtotalGivenT <- computeModelPosterior_deriv(i, t, data, 5)
allTtotalProbsGivenT$pTtotalGivenT[idx] <- probTtotalGivenT
# print(probTtotalGivenT)
idx <- idx + 1
}
#Predict Median
sum = 0
pTtotalGivenT <- allTtotalProbsGivenT$pTtotalGivenT
medi <- sum(pTtotalGivenT)/2
idx = 1
while (sum < medi && idx < length(pTtotalGivenT)) {
sum = sum + pTtotalGivenT[idx]
idx = idx + 1
}
#pred <- paste("Prediction for T-total given T = ", t, ": ", allTtotalProbsGivenT$Ttotal[idx-1])
pred <- allTtotalProbsGivenT$Ttotal[idx-1]
# print(pred)
return(pred)
}
generateMultipleNonSocialPredictions <- function(t, tMax, tMin=NULL){
# t <- 50
# tMax <- 100
tVals <- 0
if(!is.null(tMin)){
tVals <- c(tMin:tMax)
}
else{
tVals <- c(t:tMax)
}
#print(range(tVals))
df <- data.frame(t=tVals, pred=rep(0, length(tVals)))
ix = 1
for(tVal in tVals){
pred = generateNonSocialPrediction(t=tVal)
df$pred[ix] <- pred
ix = ix + 1
}
return(df)
}
df <- generateMultipleNonSocialPredictions(t=30,tMax=90)
library(ggplot2)
plt <- ggplot(data = df) + geom_line(mapping = aes(x=t, y=pred), color="blue", size=1.3) + ylab("Prediction") + ggtitle("Non-Social Podcast Duration Predictions") + theme(axis.title.x = element_text(size=20, face="bold"),
axis.title.y = element_text(size=20, face="bold"),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
plot.title = element_text(size=25, face="bold")
)+coord_cartesian(xlim=c(0,301))
plt
plt <- ggplot(data = df) + geom_line(mapping = aes(x=t, y=pred), color="blue", size=1.3) + ylab("Prediction") + ggtitle("Non-Social Podcast Duration Predictions") + theme(axis.title.x = element_text(size=20, face="bold"),
axis.title.y = element_text(size=20, face="bold"),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
plot.title = element_text(size=25, face="bold")
)+coord_cartesian(xlim=c(0,90))
plt
setwd("~/Research-REPO/social-prediction/FA21-22/Results/Social-NonSocial")
library(dplyr)
library(stringr)
library(patchwork)
library(ggfx)
story = "podcast"
plotStory <- function(story){
nonSocialPredictons <- read.csv(paste("./predictions/",story,"Predictions.csv", sep = ""))
library(ggplot2)
df <- read.csv("filtered-tidy-data.csv")
dfGrouped <- df %>% group_by(Level, Story, Context, T_val) %>% filter(Story == .env$story)
socialGroup <- dfGrouped %>% summarise(avg = mean(Prediction))
plt <- ggplot(nonSocialPredictons, aes(x=t, y=pred)) + geom_line(size=1.5, color="black")
plt <- plt+ geom_jitter(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context),size=2,alpha=0.2, width=1.2, height=3)
plt <- plt + stat_summary(dfGrouped, mapping=aes(x=T_val, y=Prediction, color=Context), size=1.3, fun.data = "mean_cl_boot")
plt <- plt + scale_color_manual(values = c("orange", "dodgerblue"))+ xlab('t') +ggtitle(str_to_title(story)) + scale_x_continuous(breaks=socialGroup$T_val)
plt <- plt + ylab('Prediction') + theme(plot.title = element_text(hjust = 0.5), axis.text = )
plt <- plt + theme(
axis.title = element_text(size=14),
axis.text = element_text(size=20),
plot.title = element_text(size=25, hjust = 0.5)
) + ggtitle(str_to_title(story)) + xlab('t')
if(story != "podcast") plt <- plt + theme(legend.position = "none")
if(story != "cake") plt <- plt + ylab("")
return(plt)
}
cakePlt = 0
moviePlt = 0
podcastPlt = 0
for(i in c("cake","movie","podcast")){
storyPlot = plotStory(i)
if(i == "cake") cakePlt = storyPlot
if(i == "movie") moviePlt = storyPlot
if(i == "podcast") podcastPlt = storyPlot
}
cakePlt + moviePlt + podcastPlt
