)+coord_cartesian(xlim=c(0,120))
plt
#Non-Social Model Predictions
library(purrr)
library(ggplot2)
computeModelPosterior_deriv<-function(t_total, t, t_total_info, flag){
#t_total        : The value of t_total in P(t_total | t)
#t              : The value of t in P(t_total | t)
#gamma           : gamma parameter (Not used in generating these predictions, leftover from implementation of original model)
#t_total_info   : a Domain Size x 2 vector, 1st column are t_total values,
#                 2nd is P(t_total)
#flag           : The story (cake, bus, drive, train) we're calculating posterior for
#                             1     2     3      4
startIndex = 0
#Vector of all t_total values
t_total_vals_vec = t_total_info[1]
#Vector of all t_total_probs
t_total_probs_vec = t_total_info[2]
num_rows = nrow(t_total_vals_vec)
for(i in (1:num_rows)){
if(t_total_info[i,1] >= t){
startIndex = i
break
}
}
para = 0.3
#The cake, bus, and drive stories all use the same utility function
if(flag == 1 || flag == 3 || flag == 2){
if(t_total - t != 0){
util = exp(1/(t_total - t))
util = util / (exp((t_total - t)*para) + util)
}
else {
util = 1
}
likelihood = (1/t_total) * util
}
# The utitlity function for the train story
else if(flag == 4){
util = exp(t_total-t)
util = util / (exp((1/(t_total - t))*para) + util)
likelihood = (1/t_total) * util
}
else likelihood = 1/t_total #Otherwise generate non-social predictions
t_prior = 0
given_t_total_prior = 0
#P(t) = sum of p(t_total)/t_total
for(i in (1:num_rows)){
t_prior = t_prior + (t_total_probs_vec[i,]/t_total_vals_vec[i,])
#Storing the t_total probability for the t_total passed as the function's parameter
if(t_total_vals_vec[i,] == t_total) given_t_total_prior = t_total_probs_vec[i,]
}
#Bayes Rules
return (likelihood * given_t_total_prior) / t_prior
}
generateNonSocialPrediction <- function(t, story=0){
# t <- 50
# t_total <- 70
data_file_path <- "C:\\Users\\paynesc\\Documents\\research\\Attempt2\\data\\Movies\\movieProbs.csv"
data <- probs #read.csv(data_file_path, header = TRUE) #
maxTtotal <- max(data$runtime)
x_space <- c(t:maxTtotal)
idx <- 1
allTtotalProbsGivenT <- data.frame(Ttotal = x_space, pTtotalGivenT = rep(maxTtotal-t))
for(i in x_space){
probTtotalGivenT <- computeModelPosterior_deriv(i, t, data, 5)
allTtotalProbsGivenT$pTtotalGivenT[idx] <- probTtotalGivenT
# print(probTtotalGivenT)
idx <- idx + 1
}
#Predict Median
sum = 0
pTtotalGivenT <- allTtotalProbsGivenT$pTtotalGivenT
medi <- sum(pTtotalGivenT)/2
idx = 1
lenpTtotal <- length(pTtotalGivenT)
while (sum < medi && idx < lenpTtotal) {
sum = sum + pTtotalGivenT[idx]
idx = idx + 1
}
#pred <- paste("Prediction for T-total given T = ", t, ": ", allTtotalProbsGivenT$Ttotal[idx-1])
pred <- allTtotalProbsGivenT$Ttotal[idx-1]
# print(pred)
return(pred)
}
generateMultipleNonSocialPredictions <- function(t, tMax, tMin=NULL){
# t <- 50
# tMax <- 100
tVals <- 0
if(!is.null(tMin)){
tVals <- c(tMin:tMax)
}
else{
tVals <- c(t:tMax)
}
#print(range(tVals))
df <- data.frame(t=tVals, pred=rep(0, length(tVals)))
ix = 1
for(tVal in tVals){
print("Generating for ")
print(tVal)
pred = generateNonSocialPrediction(t=tVal)
df$pred[ix] <- pred
ix = ix + 1
}
return(df)
}
startTimestamp <- timestamp()
##------ Thu Oct 21 02:13:24 2021 ------##
df <- generateMultipleNonSocialPredictions(t=10,tMax=120, tMin=1)
endTimestamp <- timestamp()
##------ Thu Oct 21 02:26:02 2021 ------##
plt <- ggplot(df) + geom_line(mapping = aes(x=t, y=pred), color="blue", size=1.3) + ylab("Prediction") + ggtitle("Non-Social Podcast Duration Predictions") + theme(axis.title.x = element_text(size=20, face="bold"),
axis.title.y = element_text(size=20, face="bold"),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
plot.title = element_text(size=25, face="bold")
)+coord_cartesian(xlim=c(0,120))
plt
#Non-Social Model Predictions
library(purrr)
library(ggplot2)
computeModelPosterior_deriv<-function(t_total, t, t_total_info, flag){
#t_total        : The value of t_total in P(t_total | t)
#t              : The value of t in P(t_total | t)
#gamma           : gamma parameter (Not used in generating these predictions, leftover from implementation of original model)
#t_total_info   : a Domain Size x 2 vector, 1st column are t_total values,
#                 2nd is P(t_total)
#flag           : The story (cake, bus, drive, train) we're calculating posterior for
#                             1     2     3      4
startIndex = 0
#Vector of all t_total values
t_total_vals_vec = t_total_info[1]
#Vector of all t_total_probs
t_total_probs_vec = t_total_info[2]
num_rows = nrow(t_total_vals_vec)
for(i in (1:num_rows)){
if(t_total_info[i,1] >= t){
startIndex = i
break
}
}
para = 0.3
#The cake, bus, and drive stories all use the same utility function
if(flag == 1 || flag == 3 || flag == 2){
if(t_total - t != 0){
util = exp(1/(t_total - t))
util = util / (exp((t_total - t)*para) + util)
}
else {
util = 1
}
likelihood = (1/t_total) * util
}
# The utitlity function for the train story
else if(flag == 4){
util = exp(t_total-t)
util = util / (exp((1/(t_total - t))*para) + util)
likelihood = (1/t_total) * util
}
else likelihood = 1/t_total #Otherwise generate non-social predictions
t_prior = 0
given_t_total_prior = 0
#P(t) = sum of p(t_total)/t_total
for(i in (1:num_rows)){
t_prior = t_prior + (t_total_probs_vec[i,]/t_total_vals_vec[i,])
#Storing the t_total probability for the t_total passed as the function's parameter
if(t_total_vals_vec[i,] == t_total) given_t_total_prior = t_total_probs_vec[i,]
}
#Bayes Rules
return (likelihood * given_t_total_prior) / t_prior
}
generateNonSocialPrediction <- function(t, story=0){
# t <- 50
# t_total <- 70
data_file_path <- "C:\\Users\\paynesc\\Documents\\research\\Attempt2\\data\\Podcast\\podcastProbs.csv"
data <-  read.csv(data_file_path, header = TRUE) #probs
maxTtotal <- max(data$runtime)
x_space <- c(t:maxTtotal)
idx <- 1
allTtotalProbsGivenT <- data.frame(Ttotal = x_space, pTtotalGivenT = rep(maxTtotal-t))
for(i in x_space){
probTtotalGivenT <- computeModelPosterior_deriv(i, t, data, 5)
allTtotalProbsGivenT$pTtotalGivenT[idx] <- probTtotalGivenT
# print(probTtotalGivenT)
idx <- idx + 1
}
#Predict Median
sum = 0
pTtotalGivenT <- allTtotalProbsGivenT$pTtotalGivenT
medi <- sum(pTtotalGivenT)/2
idx = 1
lenpTtotal <- length(pTtotalGivenT)
while (sum < medi && idx < lenpTtotal) {
sum = sum + pTtotalGivenT[idx]
idx = idx + 1
}
#pred <- paste("Prediction for T-total given T = ", t, ": ", allTtotalProbsGivenT$Ttotal[idx-1])
pred <- allTtotalProbsGivenT$Ttotal[idx-1]
# print(pred)
return(pred)
}
generateMultipleNonSocialPredictions <- function(t, tMax, tMin=NULL){
# t <- 50
# tMax <- 100
tVals <- 0
if(!is.null(tMin)){
tVals <- c(tMin:tMax)
}
else{
tVals <- c(t:tMax)
}
#print(range(tVals))
df <- data.frame(t=tVals, pred=rep(0, length(tVals)))
ix = 1
for(tVal in tVals){
print("Generating for ")
print(tVal)
pred = generateNonSocialPrediction(t=tVal)
df$pred[ix] <- pred
ix = ix + 1
}
return(df)
}
startTimestamp <- timestamp()
##------ Thu Oct 21 08:50:42 2021 ------##
df <- generateMultipleNonSocialPredictions(t=10,tMax=120, tMin=1)
endTimestamp <- timestamp()
##------ Thu Oct 21 08:50:42 2021 ------##
plt <- ggplot(df) + geom_line(mapping = aes(x=t, y=pred), color="blue", size=1.3) + ylab("Prediction") + ggtitle("Non-Social Podcast Duration Predictions") + theme(axis.title.x = element_text(size=20, face="bold"),
axis.title.y = element_text(size=20, face="bold"),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
plot.title = element_text(size=25, face="bold")
)+coord_cartesian(xlim=c(0,120))
plt
probs <- read.csv("episodes-sample.csv")
probs
podDur <- probs$length
str(podDur)
as.data.frame(table(podDur))
probs <- as.data.frame(table(podDur))
probs <- probs %>% filter(duration <= 400)
probs
probs <- probs %>% filter(probs <= 400)
probs$podDur <- as.numeric(probs$podDur)
summary(probs$podDur)
probs$podDur <- as.integer(probs$podDur)
summary(probs$podDur)
probs$podDur
probs <- read.csv("episodes-sample.csv")
podDur <- probs$length
podDur <- as.integer(podDur)
podDur
summary(podDur)
summary(podDur/60)
podDurt <- as.integer(podDur/60)
podDur <- as.integer(podDur/60)
podDur
summary(podDur)
probs <- as.data.frame(table(podDur))
probs
probs <- probs %>% filter(podDur <= 400)
str(probs)
probs$podDur <- as.integer(probs$podDur)
str(probs)
probs
pod <- read.csv("episodes-sample.csv")
pod
dur <- pod$length
podL <- as.data.frame(table(dur/60))
View(podL)
podL2 <- as.integer(podL$Var1)
podL2
podL2 <- data.frame(runtime = as.integer(podL$Var1), prob = podL$Freq)
podL2
str(podL2)
summary(podL2)
podcasts <- read.csv("episodes-sample.csv")
View(podcasts)
View(podcasts)
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
View(podcasts)
dur <- podcasts$length / 60
dur
summarise(dur)
summary(dur)
probs <- as.data.frame(table(dur))
probs
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
probs <- as.data.frame(table(as.integer(dur)))
probs
summary(probs$Var1)
str(probs)
probs$Var1 <- as.numeric(probs$Var1)
str(probs)
probs$Var1
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
probs <- as.data.frame(table(as.integer(dur)))
probs
summary(probs$Var1)
str(probs)
probs$Var1
as.integer(probs$Var1)
integer(probs$Var1)
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
dur <- podcasts/60
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
dur <- podcasts$length/60
dur
dur <- as.integer(dur)
dur
count(dur)
dur
summary(dur)
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
podcasts$length <- podcasts$length/60
podcasts
View(podcasts)
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
podcasts$length <- as.integer(podcasts$length/60)
podcasts
count(podcasts, 'length')
plyr::count(podcasts, 'length')
probs <- probs %>% filter(length > 0)
str(probs)
probs$Var1
as.integer(probs$Var1)
as.integer(paste(probs$Var1))
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
podcasts$length <- as.integer(podcasts$length/60)
probs <- plyr::count(podcasts, 'length')
probs <- probs %>% filter(length > 0)
probs$length <- as.integer(paste(probs$length))
probs
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
podcasts$length <- as.integer(podcasts$length/60)
probs <- plyr::count(podcasts, 'length')
str(probs)
probs <- probs %>% filter(length > 0)
probs$length <- as.integer(paste(probs$length))
probs
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
podcasts$length <- as.integer(podcasts$length/60)
probs <- plyr::count(podcasts, 'length')
str(probs)
probs <- probs %>% filter(length > 0)
probs$length <- as.integer(paste(probs$length))
probs
colnames(probs)[1] <- runtime
podcasts <- read.csv("episodes-sample.csv")
podcasts <- podcasts %>% filter(length/60 <= 400)
summary(dur)
podcasts$length <- as.integer(podcasts$length/60)
probs <- plyr::count(podcasts, 'length')
str(probs)
probs <- probs %>% filter(length > 0)
probs$length <- as.integer(paste(probs$length))
probs
colnames(probs)[1] <- "runtime"
colnames(probs)[2] <- "prob"
probs
probs
probs$prob <- probs$prob/sum(probs$prob)
probs
write.csv(probs, "nonApplePodcastProbs.csv")
write.csv(probs, "nonApplePodcastProbs.csv", row.names = FALSE)
View(probs)
str(probs)
#Non-Social Model Predictions
library(purrr)
library(ggplot2)
computeModelPosterior_deriv<-function(t_total, t, t_total_info, flag){
#t_total        : The value of t_total in P(t_total | t)
#t              : The value of t in P(t_total | t)
#gamma           : gamma parameter (Not used in generating these predictions, leftover from implementation of original model)
#t_total_info   : a Domain Size x 2 vector, 1st column are t_total values,
#                 2nd is P(t_total)
#flag           : The story (cake, bus, drive, train) we're calculating posterior for
#                             1     2     3      4
startIndex = 0
#Vector of all t_total values
t_total_vals_vec = t_total_info[1]
#Vector of all t_total_probs
t_total_probs_vec = t_total_info[2]
num_rows = nrow(t_total_vals_vec)
for(i in (1:num_rows)){
if(t_total_info[i,1] >= t){
startIndex = i
break
}
}
para = 0.3
#The cake, bus, and drive stories all use the same utility function
if(flag == 1 || flag == 3 || flag == 2){
if(t_total - t != 0){
util = exp(1/(t_total - t))
util = util / (exp((t_total - t)*para) + util)
}
else {
util = 1
}
likelihood = (1/t_total) * util
}
# The utitlity function for the train story
else if(flag == 4){
util = exp(t_total-t)
util = util / (exp((1/(t_total - t))*para) + util)
likelihood = (1/t_total) * util
}
else likelihood = 1/t_total #Otherwise generate non-social predictions
t_prior = 0
given_t_total_prior = 0
#P(t) = sum of p(t_total)/t_total
for(i in (1:num_rows)){
t_prior = t_prior + (t_total_probs_vec[i,]/t_total_vals_vec[i,])
#Storing the t_total probability for the t_total passed as the function's parameter
if(t_total_vals_vec[i,] == t_total) given_t_total_prior = t_total_probs_vec[i,]
}
#Bayes Rules
return (likelihood * given_t_total_prior) / t_prior
}
generateNonSocialPrediction <- function(t, story=0){
data_file_path <- "C:\\Users\\paynesc\\Documents\\research\\Attempt2\\data\\Podcast\\podcastProbs.csv"
#data <-  read.csv(data_file_path, header = TRUE)
data <-  probs
maxTtotal <- max(data$runtime)
x_space <- c(t:maxTtotal)
idx <- 1
allTtotalProbsGivenT <- data.frame(Ttotal = x_space, pTtotalGivenT = rep(maxTtotal-t))
for(i in x_space){
probTtotalGivenT <- computeModelPosterior_deriv(i, t, data, 5)
allTtotalProbsGivenT$pTtotalGivenT[idx] <- probTtotalGivenT
# print(probTtotalGivenT)
idx <- idx + 1
}
#Predict Median
sum = 0
pTtotalGivenT <- allTtotalProbsGivenT$pTtotalGivenT
medi <- sum(pTtotalGivenT)/2
idx = 1
lenpTtotal <- length(pTtotalGivenT)
while (sum < medi && idx < lenpTtotal) {
sum = sum + pTtotalGivenT[idx]
idx = idx + 1
}
#pred <- paste("Prediction for T-total given T = ", t, ": ", allTtotalProbsGivenT$Ttotal[idx-1])
pred <- allTtotalProbsGivenT$Ttotal[idx-1]
# print(pred)
return(pred)
}
generateMultipleNonSocialPredictions <- function(t, tMax, tMin=NULL){
# t <- 50
# tMax <- 100
tVals <- 0
if(!is.null(tMin)){
tVals <- c(tMin:tMax)
}
else{
tVals <- c(t:tMax)
}
#print(range(tVals))
df <- data.frame(t=tVals, pred=rep(0, length(tVals)))
ix = 1
for(tVal in tVals){
print("Generating for ")
print(tVal)
pred = generateNonSocialPrediction(t=tVal)
df$pred[ix] <- pred
ix = ix + 1
}
return(df)
}
startTimestamp <- timestamp()
##------ Thu Oct 21 09:55:20 2021 ------##
df <- generateMultipleNonSocialPredictions(t=10,tMax=120, tMin=1)
endTimestamp <- timestamp()
##------ Thu Oct 21 10:01:04 2021 ------##
plt <- ggplot(df) + geom_line(mapping = aes(x=t, y=pred), color="blue", size=1.3) + ylab("Prediction") + ggtitle("Non-Social Podcast Duration Predictions") + theme(axis.title.x = element_text(size=20, face="bold"),
axis.title.y = element_text(size=20, face="bold"),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
plot.title = element_text(size=25, face="bold")
)+coord_cartesian(xlim=c(0,120))
plt
read.csv("podcastDurations.csv")
df <- read.csv("podcastDurations.csv")
df
view(df)
View(df)
View(podL2)
View(probs)
View(podFilt)
